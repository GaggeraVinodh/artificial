notebooks/predicting-melbourne-housing-prices.ipynb:    "#using decision tree model\n",
python_files/ensemble/ensemble_see_this/hyper_parameters_for_random_forest_tuning.txt:each decision tree in the forest considers a random subset of features when forming questions and only has access to a random set of the training data points. This increases diversity in the forest leading to more robust overall predictions
python_files/ensemble/ensemble_see_this/hyper_parameters_for_random_forest_tuning.txt:max_depth = max number of levels in each decision tree
python_files/ensemble/ensemble_see_this/1.e-random_forests_overview.txt:Random forests or random decision forests are an ensemble learning method for classification, regression and other tasks that operates by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the ...
python_files/ensemble/ensemble_see_this/1.a-what_is_ensemble_learning_two.txt:they can combine neural networks learners, decision trees and support vector machines (SVM)
python_files/xgboost/plot_tree/plot_tree-left-to-right.py:# plot decision tree
python_files/xgboost/plot_tree/plot_tree.py:# plot decision tree
python_files/regression/random_forest_regression/ran.py:# Build a decision tree
python_files/regression/random_forest_regression/ran.py:# Make a prediction with a decision tree
python_files/regression/random_forest_regression/ran.txt:# Build a decision tree
python_files/regression/random_forest_regression/ran.txt:# Make a prediction with a decision tree
python_files/regression/boston_housing_regression/boston_housing/README.md:This is the 2nd project for the Machine Learning Engineer Nanodegree. In this project, we use the Boston Housing dataset to train an optimal decision tree algorithm to predict the best selling price of a home in Boston based on certain features of the homes and statistical analysis. 
python_files/regression/boston_housing_regression/boston_housing/README.md:Additionally, the learning and complexity curves of the decision tree model were studied to determine optimal number of training points needed as well as the maximum depth of the decision tree that minimized bias and variance in the price predictions 
python_files/regression/boston_housing_regression/boston_housing/boston_housing.ipynb:    "The following code cell produces four graphs for a decision tree model with different maximum depths. Each graph visualizes the learning curves of the model for both training and testing as the size of the training set is increased. Note that the shaded region of a learning curve denotes the uncertainty of that curve (measured as the standard deviation). The model is scored on both the training and testing sets using R<sup>2</sup>, the coefficient of determination.  \n",
python_files/regression/boston_housing_regression/boston_housing/boston_housing.ipynb:    "The following code cell produces a graph for a decision tree model that has been trained and validated on the training data using different maximum depths. The graph produces two complexity curves — one for training and one for validation. Similar to the **learning curves**, the shaded regions of both the complexity curves denote the uncertainty in those curves, and the model is scored on both the training and validation sets using the `performance_metric` function.  \n",
python_files/regression/boston_housing_regression/boston_housing/boston_housing.ipynb:    "Your final implementation requires that you bring everything together and train a model using the **decision tree algorithm**. To ensure that you are producing an optimized model, you will train the model using the grid search technique to optimize the `'max_depth'` parameter for the decision tree. The `'max_depth'` parameter can be thought of as how many questions the decision tree algorithm is allowed to ask about the data before making a prediction. Decision trees are part of a class of algorithms called *supervised learning algorithms*.\n",
python_files/regression/boston_housing_regression/boston_housing/boston_housing.ipynb:    "- Use [`DecisionTreeRegressor`](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html) from `sklearn.tree` to create a decision tree regressor object.\n",
python_files/regression/boston_housing_regression/boston_housing/boston_housing.ipynb:    "        decision tree regressor trained on the input data [X, y]. \"\"\"\n",
python_files/regression/boston_housing_regression/boston_housing/boston_housing.ipynb:    "    # TODO: Create a decision tree regressor object\n",
python_files/regression/boston_housing_regression/boston_housing/boston_housing.ipynb:    "Once a model has been trained on a given set of data, it can now be used to make predictions on new sets of input data. In the case of a *decision tree regressor*, the model has learned *what the best questions to ask about the input data are*, and can respond with a prediction for the **target variable**. You can use these predictions to gain information about data where the value of the target variable is unknown — such as data the model was not trained on."
python_files/regression/boston_housing_regression/boston_housing/boston_housing.ipynb:    "Run the code block below to fit the decision tree regressor to the training data and produce an optimal model."
python_files/regression/boston_housing_regression/boston_housing/report.html:<h3 id="Learning-Curves">Learning Curves<a class="anchor-link" href="#Learning-Curves">&#182;</a></h3><p>The following code cell produces four graphs for a decision tree model with different maximum depths. Each graph visualizes the learning curves of the model for both training and testing as the size of the training set is increased. Note that the shaded region of a learning curve denotes the uncertainty of that curve (measured as the standard deviation). The model is scored on both the training and testing sets using R<sup>2</sup>, the coefficient of determination.</p>
python_files/regression/boston_housing_regression/boston_housing/report.html:<h3 id="Complexity-Curves">Complexity Curves<a class="anchor-link" href="#Complexity-Curves">&#182;</a></h3><p>The following code cell produces a graph for a decision tree model that has been trained and validated on the training data using different maximum depths. The graph produces two complexity curves — one for training and one for validation. Similar to the <strong>learning curves</strong>, the shaded regions of both the complexity curves denote the uncertainty in those curves, and the model is scored on both the training and validation sets using the <code>performance_metric</code> function.</p>
python_files/regression/boston_housing_regression/boston_housing/report.html:<h3 id="Implementation:-Fitting-a-Model">Implementation: Fitting a Model<a class="anchor-link" href="#Implementation:-Fitting-a-Model">&#182;</a></h3><p>Your final implementation requires that you bring everything together and train a model using the <strong>decision tree algorithm</strong>. To ensure that you are producing an optimized model, you will train the model using the grid search technique to optimize the <code>'max_depth'</code> parameter for the decision tree. The <code>'max_depth'</code> parameter can be thought of as how many questions the decision tree algorithm is allowed to ask about the data before making a prediction. Decision trees are part of a class of algorithms called <em>supervised learning algorithms</em>.</p>
python_files/regression/boston_housing_regression/boston_housing/report.html:<li>Use <a href="http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html"><code>DecisionTreeRegressor</code></a> from <code>sklearn.tree</code> to create a decision tree regressor object.<ul>
python_files/regression/boston_housing_regression/boston_housing/report.html:<span class="sd">        decision tree regressor trained on the input data [X, y]. &quot;&quot;&quot;</span>
python_files/regression/boston_housing_regression/boston_housing/report.html:    <span class="c1"># TODO: Create a decision tree regressor object</span>
python_files/regression/boston_housing_regression/boston_housing/report.html:<h3 id="Making-Predictions">Making Predictions<a class="anchor-link" href="#Making-Predictions">&#182;</a></h3><p>Once a model has been trained on a given set of data, it can now be used to make predictions on new sets of input data. In the case of a <em>decision tree regressor</em>, the model has learned <em>what the best questions to ask about the input data are</em>, and can respond with a prediction for the <strong>target variable</strong>. You can use these predictions to gain information about data where the value of the target variable is unknown — such as data the model was not trained on.</p>
python_files/regression/boston_housing_regression/boston_housing/report.html:<p>Run the code block below to fit the decision tree regressor to the training data and produce an optimal model.</p>
